recap:
case 1: random
antropy will be 1

case 2: deterministic
antropy will be 0

the entropy vs probablity curve will be sad face
entrop can be used to determine probability

decision tree
4 samples
calculate antropy = 1 bc its random, 50 50 split
apply mileage
4 samples have bden split into 2 option 
if the splitted nodes are still 50 50, its antropy is also 1

how to calculate total antropy
total weighted antropy 


antropy for deterministic decision tree is deterministic
ig (root) = remainder (child)
1-(2/4 x 0 + 2/4 x 0) = 1
the one with higher information gain is better


linear regression
solution 1: gradient descent
solution 2: normal Equation



-----------------------------------------------------------
first check result after selecting each value 
income: 5A 2R vs 2A 1R
credit history: 3R vs 7A
debt: 2R 5A vs 1R 2A 

credit history is the best attribute
antropy = 0
debt and income antropy is more than 0

remainder is weighted sum of 
WEIGHTover=weight in the box/ total number of weight

7/10 x ig + 3/10 x ig 

ig = 1 - remainder(income)


higher information gain means good
if one side has all samples of the sample type,
then other side will have the further decision tree

final decision tree not even deterministic

leaf node with minimum of 3 training data
merge the bad nodes into the top and mkae it 3 bad nodes

how to mitigate influence of inconsistent data?
- preprocess data to make sure no inconsistent values
delete a data
- pruning to remove branches and nodes, min sample
pruning just take the majority
- collect more data on new features
to differentiability


1a. construct decision tree
income:
over 10k: 2R 5A 
0-10k: 1R 2A

credit history:
bad: 3R
good: 7A

debt:
low: 2R 5A
high: 1R 2A

first layer: credit history

-----------------------------------------------------------
2a.

add a bias of 1, 1, 1, 1 to X and it becomes 4x4
y is 4x1


import numpy as np

# Define the design matrix X and target vector Y
X = np.array([[1, 6, 4, 11],
              [1, 8, 5, 15],
              [1, 12, 9, 25],
              [1, 2, 1, 3]])

Y = np.array([20, 30, 50, 7])

# Calculate the coefficients using the Normal Equation
w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)

# The resulting coefficients w
print(w)


[ 4.  -5.5 -7.   7. ]
y=4 -5.5x1 -7x2 +7x3 

The matrix may not be invertible under certain conditions, typically
 when the columns of X are linearly dependent or when 
X is not full rank. This situation can occur if you 
have redundant or highly correlated features in your 
dataset. In such cases, you can consider the following 
approaches:

Feature Selection or Reduction: 
Remove or combine highly correlated features to reduce 
multicollinearity. This can make the matrix more invertible.
Regularization: Use regularization techniques like Ridge 
regression or Lasso regression, which add a penalty term 
to the cost function to prevent overfitting and help 
make the matrix invertible.


Huber Loss (Smooth Mean Absolute Error):
Huber loss is a compromise between Mean Absolute Error 
(MAE) and Mean Squared Error (MSE). It combines the 
robustness of MAE for small errors and the differentiability 
of MSE for large errors.
Huber loss uses a threshold parameter (δ) that determines 
when to switch from the quadratic (MSE-like) to the linear 
(MAE-like) component.
It is less sensitive to outliers compared to MSE and provides
 a smoother transition around the threshold.

 
 During the training of machine learning models, adjusting 
 the learning rate (α) can significantly impact the convergence 
 and performance of the model. Here are some strategies for 
 modifying the learning rate during training to enable better 
 convergence:

Learning Rate Annealing (Learning Rate Schedule):
Decreasing the learning rate over time is a common strategy. 
This process is known as learning rate annealing or scheduling.
Initially, you can start with a relatively high learning rate 
to allow the model to make large updates in the early stages of 
training. As training progresses, gradually reduce the learning rate.
Common annealing strategies include step decay (reducing the 
learning rate by a fixed factor after a certain number of epochs),
 exponential decay, or using a piecewise constant schedule.
Learning rate schedules can help the model converge faster in 
the initial phases and then fine-tune more slowly as it approaches 
convergence.

Adaptive Learning Rate Methods:
Adaptive learning rate methods dynamically adjust the learning 
rate during training based on the progress of the optimization.
Examples include Adam, RMSprop, and Adagrad. These methods use 
information about past gradients and other factors to compute 
per-parameter learning rates.
Adaptive methods can be effective in many cases because they 
automatically adjust learning rates for different parameters 
and moments in training.

Cyclical Learning Rates:
Cyclical learning rates involve periodically cycling the learning 
rate within a predefined range during training.
This approach can help the model escape local minima by temporarily
increasing the learning rate. It is known as "learning rate restarts."
It's important to choose an appropriate range for the learning rate cycle.


-----------------------------------------------------------
q3. 

MAE is better bc MSE the different is sqaured and outlier
have higher impact 

loss functions to handle outliers more gracefully
minimize influence of outliers
- huber loss = inliers use 
- log cosh loss =
differentiate between inlier and outlier

-----------------------------------------------------------
q4. 

y = x2
dy/dx = 2x
x' = x - dy/dx x learning rate
   = x - 2x x learning rate
   = x (1-2learning rate)

what can be done to learning rate of improve convergence
adjust learning rate such that it is high at the start and 
low at the end

so that at the start it can quickly go to the middle
and once it is nearing the middle/convergence 
decrease learning rate through course of training 
to make sure it ca converge and wont move to other place
